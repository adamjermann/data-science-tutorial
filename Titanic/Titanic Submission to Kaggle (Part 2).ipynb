{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Submission to Kaggle (Part 2)\n",
    "## 2nd part of my tutorial series to Kaggle.\n",
    "This is the optimization of my first solution to the Titanic competition. I use this code for the second part of my tutorial series I am writing on Medium at LINK. You find the the first part here: [https://www.kaggle.com/adamjermann/titanic/first-titanic-submission/][1].\n",
    "\n",
    "  [1]: https://www.kaggle.com/adamjermann/titanic/first-titanic-submission/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading the data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# dropping the `Cabin` and `Ticket` columns.\n",
    "data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracting the titles form the names and using it for better imputation of Age\n",
    "def name_extract(word):\n",
    "    return word.split(',')[1].split('.')[0].strip()\n",
    "titles = pd.DataFrame({'Title': data['Name'].apply(name_extract)})\n",
    "\n",
    "def title_groups(old_title):\n",
    "    if old_title == 'Mr':\n",
    "        return('Mr')\n",
    "    elif old_title == 'Mrs':\n",
    "        return('Mrs')\n",
    "    elif old_title == 'Master':\n",
    "        return('Master')\n",
    "    elif old_title == 'Miss':\n",
    "        return('Miss')\n",
    "    elif old_title == 'Master':\n",
    "        return('Master')\n",
    "    elif old_title == 'Dr':\n",
    "        return('Dr')\n",
    "    elif old_title == 'Rev':\n",
    "        return('Rev')\n",
    "    else:\n",
    "        return('Others')\n",
    "\n",
    "titles = pd.DataFrame({'Title': titles['Title'].apply(title_groups)})\n",
    "data = pd.merge(data, titles, left_index = True, right_index = True)\n",
    "table = data.pivot_table(values='Age', index=['Title'], columns=['Sex'], aggfunc=np.mean)\n",
    "def fill_age(x):\n",
    "    return table[x['Sex']][x['Title']]\n",
    "data['Age'].fillna(data[data['Age'].isnull()].apply(fill_age, axis=1), inplace=True)\n",
    "\n",
    "# drop the rest of the missing data.\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trimming outliers\n",
    "data.ix[data.Fare > 200, 'Fare'] = np.percentile(data.Fare, 98)\n",
    "\n",
    "# creating new (family size) feature\n",
    "data['Family_size'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "# encoding nominal features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data.Embarked = le.fit_transform(data.Embarked)\n",
    "data.Sex = le.fit_transform(data.Sex)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categorical_features='all')\n",
    "data_encoded = enc.fit_transform(data[['Embarked', 'Pclass']]).toarray()\n",
    "data_encoded = pd.DataFrame(data_encoded)\n",
    "data = pd.merge(data, data_encoded, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67316681929719502"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the feature matrix (with numerical features) and label vector\n",
    "X = data.drop(['PassengerId','Survived', 'Name', 'Sex', 'Embarked', 'Ticket', 'Title', 'Parch', 'SibSp'], axis=1)\n",
    "y = data.ix[:, 'Survived']\n",
    "\n",
    "# import the decision tree classifier and the cross-validation package.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create the first model and assess its accuracy.\n",
    "clf = DecisionTreeClassifier()\n",
    "cross_val_score(clf, X, y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727170236753\n",
      "{'min_samples_split': 18, 'splitter': 'random', 'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "# performing GridSearch to find the best parameters.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = np.arange(1,10)\n",
    "min_samples_leaf = np.arange(1,20,2)\n",
    "min_samples_split = np.arange(2,20,2)\n",
    "\n",
    "parameters = {'criterion': criterion, 'splitter': splitter, 'max_depth': max_depth, \n",
    "              'min_samples_leaf': min_samples_leaf, 'min_samples_split': min_samples_split}\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf = GridSearchCV(clf, parameters, cv=10)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# import the test data and have a look at it.\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform the same feature engineering steps\n",
    "data_test.drop(('Cabin'), axis=1, inplace=True)\n",
    "\n",
    "titles = pd.DataFrame({'Title': data_test['Name'].apply(name_extract)})\n",
    "titles = pd.DataFrame({'Title': titles['Title'].apply(title_groups)})\n",
    "data_test = pd.merge(data_test, titles, left_index = True, right_index = True)\n",
    "data_test['Age'].fillna(data_test[data_test['Age'].isnull()].apply(fill_age, axis=1), inplace=True)\n",
    "\n",
    "data.ix[data.Fare > 200, 'Fare'] = np.percentile(data.Fare, 98)\n",
    "data_test['Family_size'] = data_test['SibSp'] + data_test['Parch'] + 1\n",
    "\n",
    "# we need 1 plus step: we have missing values in 'Fare' as well. Lets fill in the average\n",
    "data_test['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_test.Embarked = le.fit_transform(data_test.Embarked)\n",
    "data_test.Sex = le.fit_transform(data_test.Sex)\n",
    "\n",
    "enc = OneHotEncoder(categorical_features='all')\n",
    "data_encoded = enc.fit_transform(data_test[['Embarked', 'Pclass']]).toarray()\n",
    "data_encoded = pd.DataFrame(data_encoded)\n",
    "data_test = pd.merge(data_test, data_encoded, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the feature matrix\n",
    "X_test = data_test.drop(['PassengerId', 'Name', 'Sex', 'Embarked', 'Ticket', 'Title', 'Parch', 'SibSp'], axis=1)\n",
    "\n",
    "# predict the labels for the test data\n",
    "predicted = pd.Series(clf.predict(X_test))\n",
    "\n",
    "# create a dataframe to store the prediction in the format Kaggle needs for submission.\n",
    "solution = pd.concat([data_test['PassengerId'], predicted], axis=1)\n",
    "solution.columns = ['PassengerId','Survived']\n",
    "\n",
    "# output the results in a csv\n",
    "solution.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
